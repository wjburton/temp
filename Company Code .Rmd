---
title: "BrightBytes Data Challenge"
output:
  html_notebook: default
  html_document: default
---

###Intro
**Objective**: Use this dataset to help understand what factors are the best predictors of postsecondary enrollment, and offer suggestions to operationalize those insights to help Brightbytes.

**Interpretation**: which factors are the best predictors of gaining a further education after highschool. This includes any additional including college/university and associates degreed. 

**Methodology**: Make the target binary. 1 = Post secondary (Only Bachelors for this exercise), 0 = non-post secondary (Indicated by a -7). Identify factors that are associated with higher rates of post secondary education.
Ignore variables that are asking questions about why you attended 
One key question to think about when identifying relationships: Is it the variable that makes a student more likely to go to college, or is it the type of student they are that makes them do the variable, and get a postsecondary education. 
<br>
<br>

Load libraries and data
```{r, warning = FALSE}
library(tidyverse)
df <- read_csv('/home/will/link_to_wjburton/Documents/Professional Info/Company Code Challenges/BrightBytes/HSLS_2009_v3_0/students.csv')
```

Quick data summary
```{r}
df %>% data.frame() %>% str()
df %>% summary()
df %>% head()
df %>% tail()
```
All variables are in fact integers/numeric. One issue noticed is that there are many negative values. After a quick scan on the website I found these are: 

• −5 = “Data Suppressed”—indicates values that are available on the restricted-use data
but suppressed on the public-use data.
• −7 = “Item legitimate skip/NA”—indicates items that are programmatically skipped
based on rules in the questionnaire and are not applicable to those respondents.
• −8 = “Nonrespondent/component NA”—indicates that data are not available because
of unit nonresponse or the interview component did not apply (e.g., student has no
mathematics class, thus the mathematics teacher interview does not apply).
• −9 = “Missing”—indicates item level missing where the question may apply to the
respondent but it is not answered, or the question is not administered because the
gate/introductory question is not answered.



Build modeling dataset:
Based on Data dictionary, only keep variables that would be useful for building predictive models, and rename columns to be more interpretable. (Keep variables that are known before the post secondary decision is made)
In this dataset I drop the rows that include -5, -8 or -9. -7 becomes the target, and everything > 0   becomes 1.
```{r}
table(df$S3PROGLEVEL)

pred_df <- df %>% 
      select(-one_of('X1','S3FALLHSID', 'X3STATE', 'SCH_ID', 'S3ENROLLHS13', 'S3FOCUS','S3CLGFT',
                     'S3WORKFT', 'S3CLGLVL', 'S3CLGSTATE', 'S3AAB4BA', 'S3BATRANSFER', 'S3REPUTATION',
                     'S3COSTATTEND','S3DISTANCE',
                     'S3CNSLCLG', 'S3CNSLAID', 'S3CNSLJOB', 'S3JOBPLC', 'S34YRBAPLC', 'S3SPORTS', 
                     'S3SOCIALLIFE', 'S3ONLINE', 'S3NODEBT', 'S3CANAFFORD',
                     'S3INELIGIBLE', 'S3DKHOW', 'S3DKCOULD', 'S3NOPOSTSEC', 'S3FAMNOTQUAL', 
                     'S3DONOTWANT', 'S3NOCLGOTHRSN', 'S3WHYNOTCLG', 'STU_ID')) %>% 
      rename(parent_occ = X1PAR1OCC_STEM1, socio_econ = X1SES, fafsa = S3APPFAFSA,
             location = X3LOCALE, alg1 = X3T1CREDALG1, alg2 = X3T1CREDALG2, int_math = X3T1CREDINTM,
             pre_calc = X3T1CREDPREC, stat = X3T1CREDSTAT, when_alg1 = X3TWHENALG1,
             ap_class = S3AP, ib_class = S3IB, col_clas = S3DUAL, ap_math = S3APMATH,
             ap_sci = S3APSCIENCE, ap_other = S3APOTHER, ib_math = S3IBMATH, ib_sci = S3IBSCIENCE,
             ib_other = S3IBOTHER, col_math = S3DUALMATH, col_sci = S3DUALSCIENCE, 
             col_other = S3DUALOTHER, col_influence = S3CLGINFLU,
             post_second = S3PROGLEVEL) %>% 
      filter(post_second == -7 | post_second == 1) %>% 
      mutate(post_second  = ifelse(post_second == -7,0,1)) %>% 
      mutate_if(is.integer, as.factor)
```

##Exploration
Explore variable reationships with post secondary
socio-econic

```{r}
#We are missing ~ 1000 socio economic values, but this is an incredibly strong predictor. We'll just add #an indicator if it is = -8
hist(pred_df$socio_econ)
plot_continuous(pred_df$socio_econ[pred_df$socio_econ > -8],  n = 100,
                response = pred_df$post_second[pred_df$socio_econ > -8], max_poly_degree = 1, log_odds = F, variable_name = 'Socio Economic')
```


Parent occupation
```{r}
pred_df %>% 
  group_by(parent_occ) %>% 
  summarise(pct_post_second = sum(post_second)/n(),
            n = n()) %>% 
  filter(n > 30) %>% 
  arrange(pct_post_second) %>%
  mutate(parent_occ = factor(parent_occ,levels = unique(parent_occ))) %>%
  ggplot(aes(parent_occ, pct_post_second)) + geom_bar(aes(alpha = log(n)),stat = 'identity') + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Location
```{r}
pred_df %>% 
  group_by(location) %>% 
  summarise(pct_post_second = sum(post_second)/n(),
            n = n()) %>% 
  filter(n > 30) %>% 
  arrange(pct_post_second) %>%
  mutate(location = factor(location,levels = unique(location))) %>%
  ggplot(aes(location, pct_post_second)) + geom_bar(aes(alpha = log(n)),stat = 'identity') + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

"alg1"         
```{r, echo = FALSE}
pred_df %>% 
  group_by(alg1) %>% 
  summarise(pct_post_second = sum(post_second)/n(),
            n = n()) %>% 
  filter(n > 30) %>% 
  arrange(pct_post_second) %>%
  mutate(alg1 = factor(alg1,levels = unique(alg1))) %>%
  ggplot(aes(alg1, pct_post_second)) + geom_bar(aes(alpha = n),stat = 'identity') + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

"alg2"         
```{r}
pred_df %>% 
  group_by(alg2) %>% 
  summarise(pct_post_second = sum(post_second)/n(),
            n = n()) %>% 
  filter(n > 30) %>% 
  arrange(pct_post_second) %>%
  mutate(alg1 = factor(alg2,levels = unique(alg2))) %>%
  ggplot(aes(alg2, pct_post_second)) + geom_bar(aes(alpha = n),stat = 'identity') + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

 "int_math"      
```{r}

```

"pre_calc"      
```{r}

```

"stat"          
```{r}

```

"when_alg1"     
```{r}

```

"ap_class"     
```{r}
  
```


"ib_class"     
```{r}
  
```


"col_clas"     
```{r}
  
```

"ap_math"     
```{r}
  
```

"ap_sci"     
```{r}
  
```

"ap_other"     
```{r}
  
```

        "ap_other"      "ib_math"      
"ib_sci"        "ib_other"      "col_math"      "col_sci"       "col_other"     "col_influence"
"fafsa"   















Additional Topics that aren't explored here:
What Factors are important to Post Secondary Goers (could translate to action):
S3ONLINE, S3SOCIALLIFE, S3SPORTS, S3JOBPLC, S3DISTANCE, S3COSTATTEND, S3REPUTATION

What Factors attribute to not going to post secondary (could translate to action):
S3WHYNOTCLG, S3NOCLGOTHRSN, S3DONOTWANT

FAFSA Exploration (could translate to aciton:
S3APPFAFSA, S3NODEBT, S3CANAFFORD, S3INELIGIBLE, S3DKHOW, S3DKCOULD,
S3NOPOSTSEC, S3FAMNOTQUAL








Ideas: Parents: respondants to the survey who don't know shows either 1. It is survey data and the respondents didn't care, or 2. they aren't very involved with their child's life. The 2nd may be actionable.






Functions I had built previously to visualize relationships between a continuous predictor and 
a binary response
```{r}
#'Create bins containing equal sample sizes spread across a variable
#'@description Create bins containing equal sample sizes. If the density is not
#'uniform then generic cuts in the data will not produce equal sample sizes among
#'the cuts.
#'@param variable  Variable of interest
#'@param n  The sample size for each bin
create_equal_bins <- function(variable, n){
  place <- 1:length(variable)
  n_bins <- ceiling(length(variable)/n)
  binned_var <- rep(1:n_bins,n) %>% sort %>% .[1:length(variable)]
  
  data.frame(place, variable) %>%
    arrange(variable) %>%
    mutate(binned_var = binned_var) %>%
    group_by(binned_var) %>%
    mutate(point = median(variable)) %>%
    ungroup() %>%
    arrange(place) -> out
  
  return(out)
}

#'Plot a continuous variable against a binary response
#'@description Plot a continuous variable against a binary response by
#'binning the variables and looking at the proportion of the response in each bin
#'@param variable  A binned version of the continuous variable
#'@param int An interaction term to add to the model. Can be used to fit more complicated relationships
#'@param n The number of datapoints for each condensed point
#'@param response Binary response variable
#'@param out Output the data used to create the plot or not. Accepts values of TRUE or FALSE
#'@param max_poly_degree The highest degree of polynomial to use for modeling
#'@param variable_name Name of the variable, Will be the title of the x-axis
#'@param jitter_height The random jitter of the actual points. the default may be too large or small
#'@param log_odds Should the y-axis be in terms of log odds or probability. T = log odds, F = Probability
#'@export
plot_continuous <- function(variable, int = NULL, n = 30, response, out = F,
                            max_poly_degree = 1, variable_name = 'variable',
                            jitter_height = 0.1, log_odds = T){

  df <- create_equal_bins(variable, n)
  df <- data.frame(df, response) %>% na.omit()
  
  df %>%
  group_by(point) %>%
  summarise(prob_warm = sum(response)/n(),
            n = n()) %>%
  mutate(odds = prob_warm/(1-prob_warm)) %>%
  mutate(log_odds = log(odds)) -> association_tbl

  if(is.null(int)){
    log_mod <- glm(response ~ poly(variable,max_poly_degree) ,data = df, family = "binomial") } else {
       log_mod <- glm(response ~ poly(variable,max_poly_degree) + int + I(int * variable) ,data = df, family = "binomial")
    }
  
  probs <- predict(log_mod , type = 'response')
  df$pred_prob <- probs
  df$pred_log_odds <- log(probs/(1-probs))

  max_log_odds <- max(association_tbl$log_odds[!is.infinite(association_tbl$log_odds)])
  min_log_odds <- min(association_tbl$log_odds[!is.infinite(association_tbl$log_odds)])
  add <- max(abs(association_tbl$log_odds[!is.infinite(association_tbl$log_odds)]))


  if(log_odds == T){
    df$plot_point <- ifelse(df$response == 1, max_log_odds + .1*add,
                            min_log_odds - .1*add)

    print(ggplot()+ geom_point(aes(x = association_tbl$point, y = association_tbl$log_odds)) +
            geom_line(aes(x = df$variable, y = df$pred_log_odds))+
            geom_jitter(aes(x = df$variable, y = df$plot_point),
                           color = 'blue', alpha = .05, height = jitter_height, width = 0) +
            xlab(variable_name) + ylab('log odds of making over 50k'))
  } else{
    df$plot_point <- ifelse(df$response == 1,max(df$pred_prob) + 0.15, min(df$pred_prob) - 0.15 )
    print(ggplot()+ geom_point(aes(x = association_tbl$point, y = association_tbl$prob_warm)) +
            geom_line(aes(x = df$variable, y = df$pred_prob))+
            geom_jitter(aes(x = df$variable, y = df$plot_point),
                        color = 'blue', alpha = .05, height = jitter_height, width = 0) +
            xlab(variable_name) + ylab('probability of making over 50k'))
  }

  if(out == T){
    return(list('points' = association_tbl, 'line' = df))
  }
}
  
  
  
#' Plot overlaying density plots of the variable against the response
#' @description Identify separation created by the independent variable on the response
#' @param variable independent variable
#' @param response response variable
#' @param variable_name name of independent variable or x-axis title
#' @export
plot_density <- function(variable, response, variable_name = 'variable'){
    data.frame(variable, response) %>%
    mutate(response = factor(response)) %>%
    rename(over_50k = response) -> density_plot

    print(ggplot(density_plot, aes(x = variable, fill = over_50k)) + geom_density(alpha = 0.2)+
      xlab(variable_name) + scale_fill_manual(values=c("blue", "red")))
}

```
